{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AZORIN_COHEN_Dumbo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1E9DEznYL09U","colab_type":"text"},"source":["# SET UPS"]},{"cell_type":"code","metadata":{"id":"dtYDMmvMVEHC","colab_type":"code","colab":{}},"source":["#Connect to your own Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1l7k4Cuqe7E","colab_type":"code","colab":{}},"source":["%cd \"/content/gdrive/My Drive/DeepLearningProject/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Awqh9wmKndNj","colab_type":"code","colab":{}},"source":["# Useful install\n","\n","!pip install pybind11\n","!python3 -m pybind11 --includes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PSH94fRkZwXn","colab":{}},"source":["import numpy as np\n","import golois\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","planes = 8\n","moves = 361\n","N = 100000\n","\n","input_data = np.random.randint(2, size=(N, 19, 19, planes))\n","input_data = input_data.astype ('float32')\n","\n","policy = np.random.randint(moves, size=(N,))\n","policy = keras.utils.to_categorical (policy)\n","\n","value = np.random.randint(2, size=(N,))\n","value = value.astype ('float32')\n","\n","end = np.random.randint(2, size=(N, 19, 19, 2))\n","end = end.astype ('float32')\n","golois.getBatch (input_data, policy, value, end)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeZ2E5cEL_su","colab_type":"text"},"source":["# Model definition "]},{"cell_type":"code","metadata":{"id":"rYgcKyqEWIy6","colab_type":"code","colab":{}},"source":["import tensorflow.keras as keras\n","from tensorflow.keras import layers \n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.regularizers import l2\n","\n","# Neural network\n","\n","planes = 8\n","\n","input_layer = keras.Input(\n","    shape = (19, 19, planes), \n","    name ='GoGrids'\n",")\n","\n","# CONVOLUTIONAL LAYER\n","conv_layer_1 = keras.layers.Conv2D(\n","    filters=194, \n","    kernel_size=(3,3), \n","    padding='same', \n","    use_bias=False,\n","    name='256ConvLayer-1'\n",")(input_layer) \n","\n","batch_norm1 = keras.layers.BatchNormalization(\n","    axis=-1, \n","    momentum=0.99, \n","    epsilon=0.001, \n","    center=True, \n","    scale=True, \n","    beta_initializer='zeros', \n","    gamma_initializer='ones', \n","    moving_mean_initializer='zeros', \n","    moving_variance_initializer='ones', \n","    beta_regularizer=None, \n","    gamma_regularizer=None, \n","    beta_constraint=None, \n","    gamma_constraint=None,\n","    name='BatchNorm-1'\n",")(conv_layer_1)\n","\n","conv_layer_1_activation = keras.layers.Activation(\n","    'relu'\n",")(conv_layer_1)\n","\n","\n","# RESIDUAL LAYER\n","conv_layer_2 = keras.layers.Conv2D(\n","    filters=194, \n","    kernel_size=(3,3), \n","    padding='same',\n","    use_bias=False,\n","    name='256ConvLayer-2'\n",")(conv_layer_1_activation)\n","\n","batch_norm2 = keras.layers.BatchNormalization(\n","    axis=-1, \n","    momentum=0.99, \n","    epsilon=0.001, \n","    center=True, \n","    scale=True, \n","    beta_initializer='zeros', \n","    gamma_initializer='ones', \n","    moving_mean_initializer='zeros', \n","    moving_variance_initializer='ones', \n","    beta_regularizer=None, \n","    gamma_regularizer=None, \n","    beta_constraint=None, \n","    gamma_constraint=None,\n","    name='BatchNorm-2'\n",")(conv_layer_2)\n","\n","conv_layer_2_activation = keras.layers.Activation(\n","    'relu'\n",")(conv_layer_2)\n","\n","conv_layer_3 = keras.layers.Conv2D(\n","    filters=194, \n","    kernel_size=(3,3), \n","    padding='same',\n","    use_bias=False, \n","    name='256ConvLayer-3'\n",")(conv_layer_2_activation)\n","\n","batch_norm3 = keras.layers.BatchNormalization(\n","    axis=-1, \n","    momentum=0.99, \n","    epsilon=0.001, \n","    center=True, \n","    scale=True, \n","    beta_initializer='zeros', \n","    gamma_initializer='ones', \n","    moving_mean_initializer='zeros', \n","    moving_variance_initializer='ones', \n","    beta_regularizer=None, \n","    gamma_regularizer=None, \n","    beta_constraint=None, \n","    gamma_constraint=None,\n","    name='BatchNorm-3'\n",")(conv_layer_3)\n","\n","\n","residual_layer_1 = layers.add(\n","    [conv_layer_1_activation, conv_layer_3], \n","    name='FirstResidualLayer'\n",")\n","\n","residual_layer_activation = keras.layers.Activation(\n","    'relu'\n",")(residual_layer_1)\n","\n","# POLICY HEAD\n","policy_pred = keras.layers.Conv2D(\n","    filters=2, \n","    kernel_size=(1,1), \n","    padding='same',\n","    use_bias=False,\n","    name='PolicyConv'\n",")(residual_layer_activation)\n","\n","batch_norm_policy_head = keras.layers.BatchNormalization(\n","    axis=-1, \n","    momentum=0.99, \n","    epsilon=0.001, \n","    center=True, \n","    scale=True, \n","    beta_initializer='zeros', \n","    gamma_initializer='ones', \n","    moving_mean_initializer='zeros', \n","    moving_variance_initializer='ones', \n","    beta_regularizer=None, \n","    gamma_regularizer=None, \n","    beta_constraint=None, \n","    gamma_constraint=None,\n","    name='BatchNorm-policyHead'\n",")(policy_pred)\n","\n","policy_pred_activation = keras.layers.Activation(\n","    'relu'\n",")(batch_norm_policy_head)\n","\n","flatten_policy = keras.layers.Flatten(\n","    name='PolicyFlat'\n",")(policy_pred_activation)\n","\n","policy_pred_output = keras.layers.Dense(\n","    units=361, \n","    activation = 'softmax', \n","    name='PolicyPrediction'\n",")(flatten_policy)\n","\n","\n","# VALUE HEAD\n","value_pred = keras.layers.Conv2D(\n","    filters=1, \n","    kernel_size=(1,1), \n","    padding='same', \n","    use_bias=False,\n","    name='ValueConv'\n",")(residual_layer_activation)\n","\n","batch_norm_value_head = keras.layers.BatchNormalization(\n","    axis=-1, \n","    momentum=0.99, \n","    epsilon=0.001, \n","    center=True, \n","    scale=True, \n","    beta_initializer='zeros', \n","    gamma_initializer='ones', \n","    moving_mean_initializer='zeros', \n","    moving_variance_initializer='ones', \n","    beta_regularizer=None, \n","    gamma_regularizer=None, \n","    beta_constraint=None, \n","    gamma_constraint=None,\n","    name='BatchNorm-valueHead'\n",")(value_pred)\n","\n","value_pred_activation = keras.layers.Activation(\n","    'relu'\n",")(batch_norm_value_head)\n","\n","flatten_value = keras.layers.Flatten(\n","    name='ValueFlat'\n",")(value_pred_activation)\n","\n","hidden_value_head = keras.layers.Dense(\n","    units=128, \n","    activation = 'relu', \n","    name='ValueHidden'\n",")(flatten_value)\n","\n","value_pred_output = keras.layers.Dense(\n","    units=1, \n","    activation = 'tanh', \n","    name='ValuePrediction'\n",")(hidden_value_head)\n","\n","model = keras.Model(inputs=[input_layer], outputs=[policy_pred_output, value_pred_output])\n","keras.utils.plot_model(model, show_shapes=True)\n","model.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNEtg1Q5k6k-","colab_type":"code","colab":{}},"source":["keras.utils.plot_model(\n","    model, to_file='model_Dumbo.png', show_shapes=False, show_layer_names=True,\n","    rankdir='TB', expand_nested=False, dpi=96\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JB1YYVE6Zpgc","colab_type":"code","colab":{}},"source":["# Si modèle existant\n","from tensorflow.keras.models import load_model\n","model = load_model('AZORIN_COHEN_Dumbo.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtKCNI2xKIzU","colab_type":"code","colab":{}},"source":["# Compilation\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(optimizer=sgd, loss=['categorical_crossentropy', 'mse'], loss_weights=[1, 1], metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5vh7LxM8OAII","colab_type":"text"},"source":["---------"]},{"cell_type":"code","metadata":{"id":"kK6pJ5VKK8IO","colab_type":"code","colab":{}},"source":["total_history_dict = {'PolicyPrediction_acc': [],\n","  'PolicyPrediction_loss': [],\n"," 'ValuePrediction_acc': [],\n"," 'ValuePrediction_loss': [],\n"," 'loss': [],\n"," 'val_PolicyPrediction_acc': [],\n"," 'val_PolicyPrediction_loss': [],\n"," 'val_ValuePrediction_acc': [],\n"," 'val_ValuePrediction_loss': [],\n"," 'val_loss': []}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0hsjXcwLIf3","colab_type":"code","colab":{}},"source":["# Only if the model have already been trained, load the history.\n","import pickle\n","pickle_in = open(\"file_temp.pkl\",\"rb\") #existing history dict\n","total_history_dict = pickle.load(pickle_in)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrCHs4wrLakI","colab_type":"code","colab":{}},"source":["def append_dict(total_dict, new_dict):\n","  for k,v in total_dict.items():\n","    total_dict[k] = v + new_dict[k]\n","  return total_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EbJ1o6CMYWg","colab_type":"text"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"vNyswzf2LfHr","colab_type":"code","colab":{}},"source":["for i in range (500):\n","  golois.getBatch (input_data, policy, value, end)\n","  history = model.fit(input_data, {'PolicyPrediction': policy, 'ValuePrediction': value}, epochs=1, batch_size=60, validation_split=0.05)\n","  new_dict = history.history\n","  total_history_dict = append_dict(total_history_dict, new_dict)\n","  if (i%20 == 0):\n","    model.save('AZORIN_COHEN_Dumbo.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HWjBJM3-Mceo","colab_type":"text"},"source":["# Plots"]},{"cell_type":"markdown","metadata":{"id":"XBhFLBHjMfs2","colab_type":"text"},"source":["### Policy loss"]},{"cell_type":"code","metadata":{"id":"sy3OesUadEnx","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","loss_values = total_history_dict['PolicyPrediction_loss']\n","val_loss_values = total_history_dict['val_PolicyPrediction_loss']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'b', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss', color=\"red\")\n","\n","plt.title('Policy training and validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXBcOoPOMmR8","colab_type":"text"},"source":["### Policy accuracy"]},{"cell_type":"code","metadata":{"id":"pPrXo41OaDRl","colab_type":"code","colab":{}},"source":["acc_values = total_history_dict['PolicyPrediction_acc']\n","val_acc_values = total_history_dict['val_PolicyPrediction_acc']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, acc_values, 'b', label='Training acc')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation acc', color=\"red\")\n","\n","plt.title('Policy training and validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mXtvSSGIMqMs","colab_type":"text"},"source":["### Value loss"]},{"cell_type":"code","metadata":{"id":"nGbBLjqZDOKW","colab_type":"code","colab":{}},"source":["loss_values = total_history_dict['ValuePrediction_loss']\n","val_loss_values = total_history_dict['val_ValuePrediction_loss']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, loss_values, 'b', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss', color=\"red\")\n","\n","plt.title('Value training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lDHyt9CaMtig","colab_type":"text"},"source":["### Value accuracy"]},{"cell_type":"code","metadata":{"id":"kAKL1OtRlyAF","colab_type":"code","colab":{}},"source":["acc_values = total_history_dict['ValuePrediction_acc']\n","val_acc_values = total_history_dict['val_ValuePrediction_acc']\n","\n","epochs = range(1, len(loss_values) + 1)\n","\n","plt.plot(epochs, acc_values, 'b', label='Training acc')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation acc', color=\"red\")\n","\n","plt.title('Value training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Acc')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErsYvTqYNNgA","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"E40oaQ2gl1gt","colab_type":"code","colab":{}},"source":["# Test\n","import golois\n","# Si modèle existant\n","from tensorflow.keras.models import load_model\n","\n","def compute_metrics(models_names) : \n","  golois.getBatch(input_data, policy, value, end)   \n","  accuracies_pol = [[] for model in models_names]\n","  accuracies_val = [[] for model in models_names]\n","\n","  for i, model_name in enumerate(models_names):\n","    model = load_model(model_name)\n","    test = model.evaluate(x=input_data, y={'PolicyPrediction': policy, 'ValuePrediction': value}, verbose=0)\n","    accuracies_pol[i] += test[3]\n","    accuracies_val[i] += test[4]\n","\n","  return accuracies_pol, accuracies_val\n","\n","def print_metrics(model_name, model_metrics):\n","  print(\"======================\")\n","  print(\"Model: \", model_name)\n","  print(\"accuracy_pol: \", model_metrics[0])\n","  print(\"accuracy_val: \", model_metrics[1])\n","\n","\n","### Tests\n","\n","models_names = ['dumbo_26022020.h5', 'Mowgli_residual_750.h5','Mowgli_residual_720.h5', 'Mowgli_residual_735.h5', 'AZORIN_COHEN_Dumbo.h5', 'AZORIN_COHEN_Dumber.h5', 'Mowgli_795.h5', 'AZORIN_COHEN_Cheetah']\n","\n","model_metrics = compute_metrics(models_names)\n","\n","for i, model_name in enumerate(models_names):\n","  print_metrics(model_name, model_metrics[i])\n"],"execution_count":0,"outputs":[]}]}